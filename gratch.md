\cite{gratch_creating_2002}


# summary - of 



describes the goal as "software androids" comparable to the androids and robots in film

entities can converse and collaborate, but, they live in a virtual world

the simplicity of the virtual world lets them capture the richness of human behaviour



presenting information as an expeirnces; hostorians visiting recreations

safe sandboxes for theraputic situations

comparing these "fake humans" to real ones




"Building a virtual human is a multidisciplinary effort,"

"because an agent looks like a human, people expect it to behave like one as well and will be disturbed by, or misinterpret, discrepancies from human norms."




This broad range of requirements poses a serious problem. Researchers working on particular aspects of virtual
humans cannot explore their component in the context of
a complete virtual human unless they can understand
results across this array of disciplines and assemble the
vast range of software tools (for example, speech recognizers, planners, and animation systems) required to construct one. Moreover, these tools were rarely designed to
interoperate and, worse, were often designed with different purposes in mind. For example, most computer graphics research has focused on high fidelity offline image
rendering that does not support the fine-grained interactive control that a virtual human must have over its body. 

- integration work cannot be carried out in isolatin
- e erything must work to test integration
- better if parts of the behaviours could be test in isolation, then, combined ove rtheir interfaces



In the spring of 2002, about 30 international researchers
from across disciplines convened at the University of
Southern California to begin to bridge this gap in knowledge and tools (see www.ict.usc.edu/~vhumans). Our
ultimate goal is a modular architecture and interface standards that will allow researchers in this area to reuse each
otherâ€™s work. This goal can only be achieved through a
close multidisciplinary collaboration. Towards this end,
the workshop gathered a collection of experts representing
the range of required research areas, including

- but standards can't be enforced by code; they're conventiuons
- we/I seek to develop a system that enforces these automatically

##  ??

>  As a first step, we overview the issues and available tools in three key areas of virtual human research: face-to-face conversation, emotions and personality, and human figure animation. 

### face to face

human conversation involves both language and nonverbal behaviour

- words and gestures inform their interperations 
- timescales aren't in synch

- the conversations themselves are a stream of information generated by the two actors and accomodatin the conversations's prior state

> This synchrony is essential to the meaning of conversation. When it is destroyed, as in low bandwidth videoconferencing, satisfaction and trust in the outcome of a  conversation diminishes

lists a set of required features for such a ssystem

- disucsses need for timestamping and such; i recall that i wanted to do timestamps as a component and explicit input

- feels like their discussion of TTS systems assumes that speach is bveing implemetned as a serries of events and imperative routines, rather than our/my model of a signal

- mention of the/a "Behavior Expression Animation Toolkit" which would be an interesting idea; embed that as an FRP Binding?
	- quick search doesn't turn up a project


### emotions and personality

- discusses misinc og inputs to decide what best approach should be taken?
- section feels unrelated tot eh technical concerns i'm stufying; more of a design one

### human figure animation

- the issues faced aren't "replaying" the animations, but, rahter creating the animation data
- i'm relatively certain the the section on motion capture's shortocmings is antiqueted
	- "orange duck's" paper on using ANN to synthesize animation comes to mind; not sure why
- the "relative paucity of generally available tools" has been alleviated since the paper 
- i'm not sure if the issues with facial animation are still obstaces, but, i wouldn't be surprised

- again; this section is more low level than i'd expect i need

## integration challenges

YES!

- advocates for resuable tools and modular architectures, BUT
- consistency and timing are a PITA
	- our approach should help with consistency ... i think ... becuase the FRP methods enforce "lockstep" progression
	- the explicit passing of time values should also be helpful

